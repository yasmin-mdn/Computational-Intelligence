{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CI002_HW2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwTFPzj4S1VT"
      },
      "source": [
        "# Your info\n",
        "\n",
        "Full name: Yasmin Madani\n",
        "\n",
        "Student ID: 97532265"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNvzSRkeS9B3"
      },
      "source": [
        "# Q1. Kohonen"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q1_graded\n",
        "# Do not change the above line.\n",
        "import numpy as np\n",
        "from copy import copy\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation\n",
        "import matplotlib as mpl\n",
        "from collections import Counter\n",
        "from operator import itemgetter\n",
        "from scipy import spatial\n",
        "from sklearn.metrics import pairwise_distances_argmin_min\n",
        "from IPython.display import HTML\n",
        "mpl.rcParams['animation.embed_limit'] = 500\n",
        "np.random.seed(42)\n",
        "import random"
      ],
      "metadata": {
        "id": "GAmc-AwPcNI_"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SOM"
      ],
      "metadata": {
        "id": "hzy3eNrEYgxT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Q1_graded\n",
        "class SOM_2D():\n",
        "    def __init__(self, init_lr, init_radius, radius_floor=0.6, weights_size=(20,20),  num_frames=10, lr_decay = 1, rad_decay=5, num_train=4500, num_test=500, image_dims=\"square\", epochs=10, problem=\"mnist\",):\n",
        "        x = np.load(open(\"/content/mnist_x.npy\", \"rb\"))\n",
        "        y = np.load(open(\"/content/mnist_y.npy\", \"rb\"))\n",
        "        num_train_cols = x.shape[1]\n",
        "        tot = np.concatenate((x, y), axis=1)\n",
        "        np.random.shuffle(tot)\n",
        "        x = tot[:,:num_train_cols]\n",
        "        y = tot[:,num_train_cols:]\n",
        "        sep1 = num_train \n",
        "        self.data_x = x[0:sep1]\n",
        "        self.data_y = y[0:sep1]\n",
        "        self.test_data_x = x[sep1:sep1+num_test]\n",
        "        self.test_data_y = y[sep1:sep1+num_test]\n",
        "        self.train_ind, self.test_ind = 0,0\n",
        "        self.num_train = len(self.data_x)\n",
        "        self.num_test = len(self.test_data_x)\n",
        "        \n",
        "        self.weight_dims = (weights_size[0], weights_size[1], self.data_x.shape[1])\n",
        "        self.weights = self.init_weights(self.weight_dims)\n",
        "        self.image_dims = (int(np.sqrt(self.data_x.shape[1])), int(np.sqrt(self.data_x.shape[1]))) if image_dims==\"square\" else image_dims\n",
        "        self.it_limit = epochs*num_train\n",
        "        self.num_frames = num_frames\n",
        "        self.plot_interval = self.it_limit // self.num_frames\n",
        "        self.init_lr = init_lr\n",
        "        self.lr_func = lambda t: self.init_lr*np.exp(-lr_decay*t/self.it_limit)\n",
        "        self.init_radius = init_radius\n",
        "        self.radius_func = lambda t: max([self.init_radius*np.exp(-rad_decay*t/self.it_limit), radius_floor])\n",
        "        self.neigh_func = lambda dist, rad: np.exp((-(dist**2)/(2*rad**2)))\n",
        "        self.node_winners = {i*self.weight_dims[0]+j: [] for i in range(self.weight_dims[0]) for j in range(self.weight_dims[1])}\n",
        "        self.top_nodes = {n:(0,0) for n in range(self.data_y.shape[1])}\n",
        "        \n",
        "    def get_next_train(self):\n",
        "        x, y = self.data_x[self.train_ind], self.data_y[self.train_ind]\n",
        "        self.train_ind += 1\n",
        "        if self.train_ind >= self.num_train:\n",
        "            self.train_ind = 0\n",
        "        return x, y\n",
        "    \n",
        "    def get_next_test(self):\n",
        "        x, y = self.test_data_x[self.test_ind], self.test_data_y[self.test_ind]\n",
        "        self.test_ind += 1\n",
        "        if self.test_ind >= self.num_test:\n",
        "            self.test_ind = 0\n",
        "        return x, y\n",
        "    \n",
        "    def init_weights(self, dims):\n",
        "        weights = np.random.rand(*dims)\n",
        "        return weights\n",
        "\n",
        "    def get_ord_dist(self, x, y):\n",
        "        # Calculate euclidean distance in topology space between two (x,y)-coordinates.\n",
        "        return np.linalg.norm(np.array(x)-np.array(y))\n",
        "        \n",
        "    def get_dist(self, x, y):\n",
        "        # Calculate euclidean distance between two vectors.\n",
        "        return np.linalg.norm(x-y)\n",
        "    \n",
        "    def int_to_xy(self, i):\n",
        "        # Convert an integer representation of weight index to (x,y)-coordinates.\n",
        "        return np.unravel_index(i, (self.weight_dims[0], self.weight_dims[1]))\n",
        "    \n",
        "    def update_weights(self, input_vector, bmu_index, t):\n",
        "        # Update the weights for the winning neuron and its neighborhood according to neighborhood function.\n",
        "        for i in range(self.weight_dims[0]):\n",
        "            for j in range(self.weight_dims[1]):\n",
        "                lr = self.lr_func(t)\n",
        "                radius = self.radius_func(t)\n",
        "                dist = self.get_ord_dist(bmu_index, (i,j))\n",
        "                lamb  =  self.neigh_func(dist, radius) \n",
        "                self.weights[i,j] = self.weights[i,j] + lr*lamb*(input_vector-self.weights[i,j])\n",
        "    \n",
        "    def get_winner_OLD(self, node, weights):\n",
        "        return min([((i,j), self.get_dist(node, weights[i][j])) for i in range(self.weight_dims[0]) for j in range(self.weight_dims[1])], key=lambda x: x[1])\n",
        "\n",
        "    def get_winner(self, node):\n",
        "        ind, dist = pairwise_distances_argmin_min(node.reshape(1,-1), self.weights.reshape(self.weight_dims[0]*self.weight_dims[1],-1), metric=\"cosine\")\n",
        "        return self.int_to_xy(ind[0]), dist[0] #(ind[0]//self.weight_dims[0], ind[0]-(ind[0]//self.weight_dims[0])*self.weight_dims[1]))\n",
        "    \n",
        "    def get_win_class(self, node):\n",
        "        top_labels = [x[0] for x in self.top_nodes.values()]\n",
        "        ind, dist = pairwise_distances_argmin_min(node.reshape(1,-1), self.weights.reshape(self.weight_dims[0]*self.weight_dims[1],-1)[top_labels], metric=\"cosine\")\n",
        "        return (self.int_to_xy(top_labels[ind[0]])), dist[0]\n",
        "        \n",
        "    def one_hot_to_int(self, onehot):\n",
        "        # Convert a one-hot-vector to integer.\n",
        "        return np.where(onehot==1)[0][0]\n",
        "    \n",
        "    def get_most_common(self, l):\n",
        "        # Get the most common value from a list.\n",
        "        try:\n",
        "            res = max((Counter(l).most_common(1)[0] for e in l), key=itemgetter(1))[0]\n",
        "        except ValueError:\n",
        "            res = \"NaN\"\n",
        "        return res\n",
        "    \n",
        "    def run(self):\n",
        "        # Initialize the plot that will be updated in animation.\n",
        "        fig, axmat = plt.subplots(self.weight_dims[0], self.weight_dims[1], figsize=(20,20), squeeze=True)\n",
        "        self.ims = []\n",
        "        axs = axmat.flatten()\n",
        "        for i in range(self.weight_dims[0]):\n",
        "            for j in range(self.weight_dims[1]):\n",
        "                axs[i*self.weight_dims[0]+j].set_yticklabels([])\n",
        "                axs[i*self.weight_dims[0]+j].set_xticklabels([])\n",
        "                im = axs[i*self.weight_dims[0]+j].imshow(self.weights[i,j].reshape(self.image_dims), cmap=\"gray\", animated=True)\n",
        "                self.ims.append(im)\n",
        "        fig.suptitle(\"Iteration: 0 Lr:  Radius:  \", size=30)\n",
        "        \n",
        "        def update(frame, som):\n",
        "            for iteration in range(som.plot_interval):\n",
        "                # Select a random sample for training\n",
        "                n, label = som.get_next_train()\n",
        "                # Find the neuron closest to the sample.\n",
        "                bmu_index, bmu_dist = som.get_winner(n)\n",
        "                if frame==0:\n",
        "                    break\n",
        "                # Update weights for the winning neuron and its neighborhood\n",
        "                som.update_weights(n, bmu_index, (som.plot_interval*frame)+iteration)\n",
        "                # Update dict to keep track of which cases a neuron has won.\n",
        "                som.node_winners[bmu_index[0]*som.weight_dims[0]+bmu_index[1]].append(som.one_hot_to_int(label))\n",
        "            # Calculate the majority label for a neuron.\n",
        "            som.node_labels = {k: som.get_most_common(v) for k, v in som.node_winners.items()}\n",
        "            # Get the learning rate and radius for the current iteration.\n",
        "            lr = som.lr_func(som.plot_interval*frame)\n",
        "            radius = som.radius_func(som.plot_interval*frame)\n",
        "            # Calculate train and test accuracy.\n",
        "            train_acc = som.get_train_acc()\n",
        "            test_acc = som.get_test_acc()\n",
        "            # Update plot title\n",
        "            fig.suptitle(\"Iteration: \"+str(frame*som.plot_interval)+ \" Lr: {:0.2f}\".format(lr) +\n",
        "                         \" Radius: {:0.2f}\".format(radius)+\"\\n Train acc: {:0.2f}\".format(train_acc)+\" Test acc: {:0.2f}\".format(test_acc) , size=50)\n",
        "            # Update images from weight arrays and set title according to majority label.\n",
        "            for i in range(som.weight_dims[0]):\n",
        "                for j in range(som.weight_dims[1]):\n",
        "                    som.ims[i*som.weight_dims[0]+j].set_array(som.weights[i,j].reshape(som.image_dims))\n",
        "                    axs[i*som.weight_dims[0]+j].set_title(str(som.node_labels[i*som.weight_dims[0]+j]), size=12, fontweight=\"bold\")\n",
        "            return som.ims\n",
        "        \n",
        "        animation = mpl.animation.FuncAnimation(fig, func=update, blit=True, interval=100, frames=self.num_frames+1, fargs=[self]);\n",
        "        plt.close(fig)\n",
        "        return animation\n",
        "    \n",
        "    def get_train_acc(self):\n",
        "        # Calculation fraction correct predictions on the training data given the majority label as a classifier.\n",
        "        num_correct = 0\n",
        "        for iteration in range(self.num_train):\n",
        "            n, label = self.get_next_train()\n",
        "            bmu_index, bmu_dist = self.get_winner(n)\n",
        "            if self.one_hot_to_int(label) == self.node_labels[bmu_index[0]*self.weight_dims[0]+bmu_index[1]]:\n",
        "                num_correct += 1\n",
        "        acc = num_correct/self.num_train\n",
        "        return acc\n",
        "    \n",
        "    def get_test_acc(self):\n",
        "        # Calculation fraction correct predictions on the test data given the majority label as a classifier.\n",
        "        num_correct = 0\n",
        "        for iteration in range(self.num_test):\n",
        "            n, label = self.get_next_test()\n",
        "            bmu_index, bmu_dist = self.get_winner(n)\n",
        "            # Check if the input vectors label matches the winning neurons majority label.\n",
        "            if self.one_hot_to_int(label) == self.node_labels[bmu_index[0]*self.weight_dims[0]+bmu_index[1]]:\n",
        "                num_correct += 1\n",
        "        acc = num_correct/self.num_test\n",
        "        return acc\n",
        "    \n",
        "    def test(self):\n",
        "        # Plot a random sample from the test set and display the input image and weight of the winning neuron for that input.\n",
        "        test, label = self.get_test_sample()\n",
        "        fig, (inp_ax, win_ax) = plt.subplots(2, figsize=(10,10))\n",
        "        inp_ax.imshow(test.reshape((self.image_dims[0], self.image_dims[1])), cmap=\"gray\")\n",
        "        true_label = self.one_hot_to_int(label)\n",
        "        inp_ax.set_title(str(true_label))\n",
        "        winner, dist = self.get_winner(test)\n",
        "        win_ax.imshow(self.weights[winner].reshape((self.image_dims[0], self.image_dims[1])), cmap=\"gray\")\n",
        "        winners_label = self.node_labels[winner[0]*self.weight_dims[0]+winner[1]]\n",
        "        win_ax.set_title(str(winners_label))\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "5s54Du_04k02"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Q1_graded\n",
        "mnistparams = {}\n",
        "mnistsom = SOM_2D(0.2, 2.5, 0.50,(20,20),10,1.1,5,4500,500,\"square\",10)\n",
        "anim = mnistsom.run()\n",
        "#HTML(anim.to_jshtml())"
      ],
      "metadata": {
        "id": "ZjSpevbr9rZL"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsOQnvVSTCT5"
      },
      "source": [
        "# Q4. RBF\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q4_graded\n",
        "# Do not change the above line.\n",
        "from re import X\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pylab as plt\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "v1JmQyrSdjAt"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Q4_graded\n",
        "# Do not change the above line.\n",
        "n=200\n",
        "X_lst=[]\n",
        "Y_lst=[]\n",
        "def make_dataset(n):\n",
        "  for i in range(0,n):\n",
        "      x=random.uniform(0,1)\n",
        "      X_lst.append(x)\n",
        "      mu=random.uniform(-0.2,0.2)\n",
        "      y=1/3 + 0.5*np.sin(3*x*np.pi)+mu\n",
        "      Y_lst.append(y)\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X_lst, Y_lst,test_size=0.2)\n",
        "  return (X_train, X_test, y_train, y_test)\n",
        "\n",
        "X_train, X_test, y_train, y_test= make_dataset(n)\n",
        "X= np.array(X_train)\n",
        "Y = np.array(y_train)\n",
        "X_Test= np.array(X_test)\n",
        "Y_Test= np.array(y_test)"
      ],
      "metadata": {
        "id": "nzZMO-JumT8-"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Q4_graded\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_shape=(1,), activation='tanh'))\n",
        "model.add(Dense(64, activation='tanh'))\n",
        "model.add(Dense(32, activation='tanh'))\n",
        "model.add(Dense(16, activation='tanh'))\n",
        "model.add(Dense(1, activation='tanh'))\n",
        "model.compile(loss='mean_squared_error', optimizer='Adam')\n",
        "result=model.fit(X, Y, epochs=1000, batch_size=30,verbose=0)\n",
        "y_predict = model.predict(X)\n",
        "plt.plot(X, Y, 'bo', X, y_predict, 'go')\n",
        "plt.ylabel('Y / Predicted Value')\n",
        "plt.xlabel('X Value')\n",
        "plt.show()\n",
        "y_Test_predict = model.predict(X_Test)\n",
        "plt.plot(X_Test, Y_Test, 'bo', X_Test, y_Test_predict, 'ro')\n",
        "plt.ylabel('Y / Predicted Value')\n",
        "plt.xlabel('X Test Value')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "18a3k8JZsarH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Q4_graded\n",
        "np.random.seed(1)\n",
        "def rbf(x, center, radius):\n",
        "  return np.exp(-1 / (2 * radius ** 2) * (x - center) ** 2)\n",
        "def kmeans(X, k):\n",
        "  clusters = np.random.choice(np.squeeze(X), size=k)\n",
        "  prevClusters = clusters.copy()\n",
        "  stds = np.zeros(k)\n",
        "  converged = False\n",
        "\n",
        "  while not converged:\n",
        "    distances = np.squeeze(np.abs(X[:, np.newaxis] - clusters[np.newaxis, :]))\n",
        "    closestCluster = np.argmin(distances, axis=1)\n",
        "\n",
        "    for i in range(k):\n",
        "      pointsForCluster = X[closestCluster == i]\n",
        "      if len(pointsForCluster) > 0:\n",
        "        clusters[i] = np.mean(pointsForCluster, axis=0)\n",
        "\n",
        "    converged = np.linalg.norm(clusters - prevClusters) < 1e-6\n",
        "    prevClusters = clusters.copy()\n",
        "\n",
        "  distances = np.squeeze(np.abs(X[:, np.newaxis] - clusters[np.newaxis, :]))\n",
        "  closestCluster = np.argmin(distances, axis=1)\n",
        "\n",
        "  clustersWithNoPoints = []\n",
        "  for i in range(k):\n",
        "    pointsForCluster = X[closestCluster == i]\n",
        "    if len(pointsForCluster) < 2:\n",
        "      clustersWithNoPoints.append(i)\n",
        "      continue\n",
        "    else:\n",
        "      stds[i] = np.std(X[closestCluster == i])\n",
        "\n",
        "  if len(clustersWithNoPoints) > 0:\n",
        "    pointsToAverage = []\n",
        "    for i in range(k):\n",
        "      if i not in clustersWithNoPoints:\n",
        "        pointsToAverage.append(X[closestCluster == i])\n",
        "\n",
        "    pointsToAverage = np.concatenate(pointsToAverage).ravel()\n",
        "    stds[clustersWithNoPoints] = np.mean(np.std(pointsToAverage))\n",
        "\n",
        "  return clusters, stds\n",
        "\n",
        "class RBF():\n",
        "  def __init__(self, k):\n",
        "    self.k = k\n",
        "    self.w = np.random.randn(k)\n",
        "    self.b = np.random.randn(1)\n",
        "\n",
        "    self.centers = None\n",
        "    self.stds = None\n",
        "\n",
        "    self.iterations = None\n",
        "    self.learning_rate = None\n",
        "\n",
        "  def predict(self, x):\n",
        "    y_predict = []\n",
        "    for i in range(x.shape[0]):\n",
        "      z = np.array([rbf(x[i], center, sigma) for center, sigma, in zip(self.centers, self.stds)])\n",
        "      a = z.T.dot(self.w) + self.b\n",
        "      y_predict.append(a)\n",
        "    return np.array(y_predict)\n",
        "\n",
        "  def update_parameters(self, a, error):\n",
        "    self.w = self.w - self.learning_rate * a * error\n",
        "    self.b = self.b - self.learning_rate * error\n",
        "\n",
        "  def fit(self, x, y, iterations, learning_rate):\n",
        "    self.iterations = iterations\n",
        "    self.learning_rate = learning_rate\n",
        "    self.centers, self.stds = kmeans(x, self.k)\n",
        "\n",
        "    # SGD\n",
        "    for i in range(self.iterations):\n",
        "      for j in range(x.shape[0]):\n",
        "        z = np.array([rbf(x[j], center, sigma) for center, sigma, in zip(self.centers, self.stds)])\n",
        "        a = z.T.dot(self.w) + self.b\n",
        "        difference = y[j] - a\n",
        "        loss = (difference.flatten() ** 2) / 2\n",
        "        error = (-1) * difference.flatten()\n",
        "        self.update_parameters(z, error)\n",
        "\n",
        "ITERATIONS = 500\n",
        "LEARNING_RATE = 0.01\n",
        "\n",
        "my_rbf = RBF(k=3)\n",
        "my_rbf.fit(X, Y, ITERATIONS, LEARNING_RATE) \n",
        "y_predict = my_rbf.predict(X) \n",
        "plt.plot(X, Y, 'bo', X, y_predict, 'ro')\n",
        "plt.ylabel('Y / Predicted Value')\n",
        "plt.xlabel('X Value')\n",
        "plt.show()\n",
        "\n",
        "y_predict = my_rbf.predict(X_Test) \n",
        "plt.plot(X_Test, Y_Test, 'bo', X_Test, y_predict, 'go')\n",
        "plt.ylabel('Y / Predicted Value')\n",
        "plt.xlabel('X_Test Value')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xxOvVPQI6Bh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRqYhKw1rgUp"
      },
      "source": [
        "# <font color='red'>Submission</font>\n",
        "\n",
        "1. Sign up in [Gradescope](https://www.gradescope.com) with proper name and student ID.\n",
        "2. Fill in your full name (seperated by single spaces) and student ID in the beginning of this notebook.\n",
        "3. After you're done with this notebook, you should do the following:\n",
        "  - Clear all outputs of the notebook.\n",
        "  ![clear all outputs](https://i.ibb.co/y6FrttB/Screen-Shot-2021-03-21-at-01-51-42.png)\n",
        "  - Run all of the cells (if you skipped a question just leave the cell unchanged), and make sure all of your outputs are correct.\n",
        "  ![run all](https://i.ibb.co/cgRcBZ0/Screen-Shot-2021-03-21-at-01-54-58.png)\n",
        "  - Save your notebook.\n",
        "  \n",
        "  - If you're using Colab, download your notebook.\n",
        "  ![download ipynb](https://i.ibb.co/2KxYM6K/Screen-Shot-2021-03-21-at-02-03-50.png)\n",
        "  \n",
        "  - Put the notebook file you just downloaded and `convert.py` in the same folder run the following command:\n",
        "  ```bash\n",
        "  python convert.py\n",
        "  ```\n",
        "  This will export your code for each question into a `.py` file.\n",
        "    - **Note**: if you want to add more cells, add this to the **first** line of the cell:\n",
        "  ```python\n",
        "  # Q1_graded\n",
        "  ```\n",
        "  according to the question number.\n",
        "  - There are 2 assignments in Gradescope:\n",
        "\n",
        "    ![assignments](https://i.ibb.co/bdpVdvr/image.png)\n",
        "  \n",
        "    You should upload your **codes** and your **notebook** in `HW2` section and your final report for all of the questions as a **single pdf** file in `HW2 - Report`. Autograder will automatically check for:\n",
        "    - `CI002_HW2.ipynb`\n",
        "    - `Q1.py`\n",
        "    - `Q4.py`\n",
        "    - Your name and ID in the beginning of `.ipynb` file.\n",
        "\n",
        "    It is important that you <font color='red'>**don't**</font> change the names of these files before submission.\n",
        "\n",
        "4. If you pass the autograder, you're good to go."
      ]
    }
  ]
}